{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane Detection (for single image)\n",
    "https://www.hackster.io/kemfic/simple-lane-detection-c3db2f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r\"C:\\Users\\renac\\Downloads\\NUS\\Y3S1\\DSA3101\\project\\images\\2022_01_05_21_10\\1701_2103_20220105210501_22826b.jpg\" # image at 2110\n",
    "img = cv2.imread(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(img_name, img):\n",
    "    cv2.namedWindow(img_name, cv2.WINDOW_NORMAL) # fit image to window\n",
    "    cv2.imshow(img_name, img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROI\n",
    "To mask out region of interest in image\n",
    "- obtain relevant shape coordinates by clicking on displayed image (min. 4 coordinates required)\n",
    "- use coordinates to obtain mask image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Shape Coordinates\n",
    "https://www.geeksforgeeks.org/displaying-the-coordinates-of-the-points-clicked-on-the-image-using-python-opencv/\n",
    "\n",
    "https://stackoverflow.com/questions/23596511/how-to-save-mouse-position-in-variable-using-opencv-and-python\n",
    "\n",
    "https://stackoverflow.com/questions/35003476/opencv-python-how-to-detect-if-a-window-is-closed/37881722#37881722"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeCoords:\n",
    "    def __init__(self):\n",
    "        self.points = []\n",
    "    \n",
    "    def click_event(self, event, x, y, flags, params):\n",
    "        # checking for left mouse clicks, display in shell if found\n",
    "        if event == cv2.EVENT_LBUTTONDOWN or event==cv2.EVENT_RBUTTONDOWN:\n",
    "            self.points.append((x, y))\n",
    "            # print(x, ' ', y)\n",
    "            # displaying the coordinates on the image window\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            text = '(' + str(x) + ', ' + str(y) + ')'\n",
    "            display_img = img.copy()\n",
    "            cv2.putText(display_img, text, (x,y), font, 0.8, (255, 0, 0), 2)\n",
    "            cv2.imshow('image', display_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_coords = ShapeCoords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL) # fit image to window\n",
    "cv2.setMouseCallback('image', shape_coords.click_event)\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "while cv2.getWindowProperty('image', cv2.WND_PROP_VISIBLE) > 0:\n",
    "    keyCode = cv2.waitKey(50)\n",
    "    # close window when key q or esc is pressed\n",
    "    if keyCode == 99 or keyCode == 27:\n",
    "        break\n",
    "    # print(cv2.waitKey())\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(95, 1070), (1359, 136), (1598, 135), (1535, 1073)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords = shape_coords.points\n",
    "coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masking Out ROI\n",
    "https://www.hackster.io/kemfic/simple-lane-detection-c3db2f\n",
    "\n",
    "https://pyimagesearch.com/2021/01/19/image-masking-with-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi(img, coords):\n",
    "    x = int(img.shape[1])\n",
    "    y = int(img.shape[0])\n",
    "    if len(coords) < 4:\n",
    "        print('minimum 4 coordinates required')\n",
    "        return\n",
    "    shape = np.array(coords) # shape of roi\n",
    "    mask = np.zeros_like(img) # np array with zeros (of image dimension)\n",
    "\n",
    "    # creates a polygon with the mask colour (blue), areas not in roi would be black (pixel is 0)\n",
    "    cv2.fillPoly(mask, pts=np.int32([shape]), color=(255,255,255))\n",
    "\n",
    "    # select ares where mask pixels are not zero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_img = roi(img, coords)\n",
    "display_image('ROI Image', roi_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colour Filtering / Masking\n",
    "To obtain white & yellow lines from roads\n",
    "- yellow lane lines: get rid of pixels with a hue value outside of 10 and 50 + high Saturation value\n",
    "- white lane lines: get rid of pixels that have a lightness value < 190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yellow lane lines: get rid of pixels with a hue value outside of 10 and 50 + high Saturation value\n",
    "# white lane lines: get rid of pixels that have a lightness value < 190\n",
    "def filter_white_yellow(img):\n",
    "    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # convert to rgb\n",
    "\n",
    "    #convert to HLS to mask based on HLS\n",
    "    hls_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2HLS) # hue, lightness, saturation\n",
    "\n",
    "    # white mask\n",
    "    lower = np.array([0,190,0]) # lower bound for white\n",
    "    upper = np.array([255,255,255]) # upper bound for white\n",
    "    white_mask = cv2.inRange(hls_img, lower, upper)\n",
    "\n",
    "    # yellow mask\n",
    "    yel_lower = np.array([10,0,90]) # lower bound for yellow\n",
    "    yel_upper = np.array([50,255,255]) # upper bound for yellow\n",
    "    yellow_mask = cv2.inRange(hls_img, yel_lower, yel_upper)\n",
    "    \n",
    "    mask = cv2.bitwise_or(yellow_mask, white_mask)\n",
    "    masked = cv2.bitwise_and(rgb_img, rgb_img, mask = mask)\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_img = filter_white_yellow(roi_img)\n",
    "display_image('Filtered Image', filter_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny Edge Detection\n",
    "To obtain edges of lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny(img):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    blur_gray = cv2.GaussianBlur(gray_img, (5, 5), sigmaX=0, sigmaY=0) # can change kernel size\n",
    "    return cv2.Canny(gray_img, 200, 700) # to set upper & lower threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_img = canny(filter_img)\n",
    "display_image('Canny Image', canny_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Test Canny Threshold\n",
    "https://stackoverflow.com/questions/25125670/best-value-for-threshold-in-canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(x):\n",
    "    print(x)\n",
    "\n",
    "canny = cv2.Canny(filter_img, 85, 255) \n",
    "\n",
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "cv2.createTrackbar('L', 'image', 100, 1000, callback) #lower threshold trackbar for window image\n",
    "cv2.createTrackbar('U', 'image', 100, 1000, callback) #upper threshold trackbar for window image\n",
    "\n",
    "while(1):\n",
    "    # concat_img = cv2.hconcat([filter_img, canny])\n",
    "    cv2.imshow('image', filter_img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27 or k == 99: # escape key or q\n",
    "        break\n",
    "    l = cv2.getTrackbarPos('L', 'image')\n",
    "    u = cv2.getTrackbarPos('U', 'image')\n",
    "\n",
    "    canny = cv2.Canny(filter_img, l, u)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05c181a2f892d70e2e4938953707a4601cdad30f805c5da25590eb6c9b5fe8b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
